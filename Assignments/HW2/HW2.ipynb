{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.) Perceptron Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron (object) :\n",
    "\n",
    "    def __init__(self , eta=0.01, n_iter=50, random_state=1):\n",
    "        self.eta = eta\n",
    "        self.n_iter=n_iter\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def train(self, X, y):\n",
    "        rgen = np.random.RandomState(self.random_state)\n",
    "        self.w_ = rgen.normal(loc=0.0, scale=0.01, size=1 + X.shape[1])\n",
    "        self.errors_ = []\n",
    "        for _ in range(self.n_iter):\n",
    "            errors = 0\n",
    "            for xi, target in zip(X, y):\n",
    "                update = self.eta * (target - self.predict(xi)) # ðœ‚ ð‘¦ C âˆ’ Ið‘¦ C\n",
    "                self.w_[1:] += update * xi\n",
    "                self.w_[0] += update\n",
    "                errors += int(update != 0.0)\n",
    "            self.errors_.append(errors)\n",
    "        return self.errors_ \n",
    "\n",
    "    def net_input(self, X):\n",
    "        return np.dot(X, self.w_[1:]) + self.w_[0]\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return np.where(self.net_input(X) >= 0.0, 1, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2.) Adaline Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adaline():\n",
    "    def __init__(self, eta=0.01, n_iter=50, random_state=1):\n",
    "        self.eta = eta\n",
    "        self.n_iter = n_iter\n",
    "        self.random_state = random_state\n",
    "        self.w_ = None\n",
    "        self.cost_ = []\n",
    "        self.rgen = np.random.RandomState(self.random_state)\n",
    "\n",
    "    \n",
    "    def train(self, X, y):\n",
    "        self.w_ = self.rgen.normal(loc=0.0, scale=0.01, size=1 + X.shape[1])\n",
    "        self.cost_ = []\n",
    "        for _ in range(self.n_iter):\n",
    "            net_input = self.net_input(X)\n",
    "            output = net_input\n",
    "            errors = (y - output)\n",
    "            self.w_[1:] += self.eta * X.T.dot(errors)\n",
    "            self.w_[0] += self.eta * errors.sum()\n",
    "            cost = (errors**2).sum() / 2.0\n",
    "            self.cost_.append(cost)\n",
    "        return self.cost_\n",
    "    \n",
    "    def net_input(self, X):\n",
    "        return np.dot(X, self.w_[1:]) + self.w_[0]\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.where(self.net_input(X) >= 0.0, 1, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3.) Stochastic Gradient Descent(SGD) Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdalineWithSGD(Adaline):\n",
    "\n",
    "    def _shuffle(self, X, y):\n",
    "        r = self.rgen.permutation(len(y))\n",
    "        return X[r], y[r]\n",
    "\n",
    "    def _update_weights(self, xi, target):\n",
    "        output = self.net_input(xi)\n",
    "        error = (target - output)\n",
    "        self.w_[1:] += self.eta * xi.dot(error)\n",
    "        self.w_[0] += self.eta * error\n",
    "        cost = 0.5 * error**2\n",
    "        return cost\n",
    "\n",
    "    def train(self, X, y):\n",
    "        self.w_ = self.rgen.normal(loc=0.0, scale=0.01, size=1 + X.shape[1])\n",
    "        self.cost_ = []\n",
    "    \n",
    "        for _ in range(self.n_iter):\n",
    "            X, y = self._shuffle(X, y)\n",
    "            cost = []\n",
    "            for xi, target in zip(X, y):\n",
    "                cost.append(self._update_weights(xi, target))\n",
    "            avg_cost = sum(cost) / len(y)\n",
    "            self.cost_.append(avg_cost)\n",
    "        return self.cost_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4, Q5 & Q7.) Program to test Different Classifiers and Multiclass Classifier Using One-vs-Rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class tester(object):\n",
    "\n",
    "    classifiers = ['perceptron', 'adaline', 'sgd']\n",
    "\n",
    "    def __init__(self, classifier_name, data_location) -> None:\n",
    "        self.classifier_name = classifier_name\n",
    "        self.data_location = data_location  \n",
    "        self.classifier = self.validateAndInstantiate()     \n",
    "\n",
    "    def validateAndInstantiate(self):\n",
    "        if self.classifier_name not in self.classifiers: # Checking if the classifier name is valid\n",
    "            Exception('Classifier name must be one of: ' + str(self.classifiers))\n",
    "        if self.classifier_name == 'perceptron':\n",
    "            classifier = Perceptron(eta=0.1, n_iter=1500)\n",
    "        elif self.classifier_name == 'adaline':\n",
    "            classifier = Adaline(eta=0.00001, n_iter=500, random_state=1)\n",
    "        elif self.classifier_name == 'sgd':\n",
    "            classifier = AdalineWithSGD(eta=0.001, n_iter=100, random_state=1)\n",
    "        return classifier\n",
    "    \n",
    "    def loadData(self, separator=',', class_column_index=-1, positive_class_value=0):\n",
    "        # Importing the dataset\n",
    "        df = pd.read_csv(self.data_location, sep=separator, header=None)\n",
    "\n",
    "        # shuffle the data\n",
    "        df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "        # Separate the data into features and the class column\n",
    "        y = df.iloc[:, class_column_index].values\n",
    "\n",
    "        # drop the class column\n",
    "        X = df.drop(df.columns[class_column_index], axis=1)\n",
    "\n",
    "        \n",
    "        # get unique class value from dataframe; since its already randomized, we can just take the first value\n",
    "        positive_class = np.sort(np.unique(y))[positive_class_value]\n",
    "\n",
    "        print(positive_class)\n",
    "        # 1 positive and other negative class\n",
    "        y = np.where(y == positive_class, -1, 1) # Convert the class labels to two integer\n",
    "        X = X.values\n",
    "\n",
    "        # Feature Scaling\n",
    "        # Normalize the data to have mean=0 and standard deviation=1\n",
    "        for i in range(X.shape[1]):\n",
    "            X[:, i] = (X[:, i] - X[:, i].mean()) / X[:, i].std()\n",
    "        \n",
    "        # Splitting the dataset into the Training set and Test set \n",
    "        percent = int(0.7 * len(y))\n",
    "        self.X_train = X[:percent, :]\n",
    "        self.y_train = y[:percent]\n",
    "        self.X_test = X[percent:, :]\n",
    "        self.y_test = y[percent:]\n",
    "\n",
    "    \n",
    "    def results(self):\n",
    "        self.classifier.train(self.X_train, self.y_train)\n",
    "        y_pred = self.classifier.predict(self.X_test)\n",
    "        # Performance metrics: Accuracy\n",
    "        accuracy = np.sum(y_pred == self.y_test) / len(self.y_test)\n",
    "        # Print Accuracy in percentage\n",
    "        print('Accuracy: ' + str(100 * np.mean((y_pred == self.y_test).astype(float))) + '%')\n",
    "        \n",
    "        print('The classifier failed to predict the class of {} samples'.format(np.sum(y_pred != self.y_test)))\n",
    "        # print(pd.crosstab(self.y_test, y_pred, rownames=['True'], colnames=['Predicted'], margins=True))\n",
    "        return accuracy\n",
    "\n",
    "    def train(self):\n",
    "        return self.classifier.train(self.X_train, self.y_train) \n",
    "\n",
    "    def to_string(self):\n",
    "        return self.classifier_name + ' ' + 'learning rate: ' + str(self.classifier.eta)\n",
    "\n",
    "models = tester.classifiers\n",
    "\n",
    "# (data_location, class_column_index, no_of_classes)\n",
    "datasets = [('http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data',-1,3), \n",
    "    ('http://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data',0, 3)]\n",
    "\n",
    "# iterate across all models and datasets and add the training_cost to subplots \n",
    "\n",
    "fig, axs = plt.subplots(3, 2)\n",
    "\n",
    "accuracies = []\n",
    "for i, model  in enumerate(models):\n",
    "    accuracy_list_model = []\n",
    "    for j, (dataset, class_col_idx, no_of_classes) in enumerate(datasets):\n",
    "        testerObj = tester(model, dataset)\n",
    "\n",
    "        ### Q7.) Multiclass Classification Using One-vs-Rest with SGD\n",
    "        \n",
    "        # pick class with highest confidence\n",
    "        per_class_accuracy = 0\n",
    "        per_class_cost  = []\n",
    "        for k in range(no_of_classes):\n",
    "            testerObj.loadData(class_column_index=class_col_idx, positive_class_value=k)\n",
    "            training_cost = testerObj.train()\n",
    "            accuracy = testerObj.results()\n",
    "\n",
    "            if(accuracy > per_class_accuracy):\n",
    "                per_class_accuracy = accuracy\n",
    "                per_class_cost = training_cost\n",
    "\n",
    "        # collect accuracy to a list\n",
    "        accuracy_list_model.append(per_class_accuracy)  \n",
    "\n",
    "        # Add the training_cost to subplots\n",
    "        plt.subplot(len(models), len(datasets), models.index(model) * len(datasets) + datasets.index((dataset,class_col_idx,no_of_classes)) + 1)\n",
    "        axs[i, j].plot(range(1, len(training_cost) + 1), training_cost, marker='o')\n",
    "        axs[i, j].set_title(testerObj.to_string())\n",
    "    accuracies.append(accuracy_list_model)\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Average Cost')\n",
    "plt.show()\n",
    "                \n",
    "\n",
    "\n",
    "# Print the test accuracy for each model and dataset\n",
    "table = plt.table(cellText=accuracies, rowLabels=models, colLabels=['iris','wine'], loc='center')\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(10)\n",
    "plt.axis('off')\n",
    "plt.title('Test Accuracy for each model and dataset')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
